{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcfc7186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 19:13:46.417196: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-16 19:13:46.822506: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-16 19:13:46.997443: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-16 19:13:47.110216: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-16 19:13:47.111202: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-16 19:13:47.321385: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-16 19:13:48.730476: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "For a model with multiple outputs, when providing the `metrics` argument as a list, it should have as many entries as the model has outputs. Received:\nmetrics=['accuracy']\nof length 1 whereas the model has 2 outputs.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, [y_t1_train, y_t2_train], epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test, [y_t1_test, y_t2_test]))\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     67\u001b[0m evaluation \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, [y_t1_test, y_t2_test])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/trainers/compile_utils.py:250\u001b[0m, in \u001b[0;36mCompileMetrics._build_metrics_set\u001b[0;34m(self, metrics, num_outputs, output_names, y_true, y_pred, argument_name)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(metrics, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(metrics) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_pred):\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    251\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor a model with multiple outputs, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    252\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen providing the `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margument_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` argument as a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist, it should have as many entries as the model has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    254\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs. Received:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00margument_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mof \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    255\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(metrics)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m whereas the model has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    256\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(y_pred)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m outputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m         )\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (mls, yt, yp) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mzip\u001b[39m(metrics, y_true, y_pred)\n\u001b[1;32m    260\u001b[0m     ):\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mls, \u001b[38;5;28mlist\u001b[39m):\n",
      "\u001b[0;31mValueError\u001b[0m: For a model with multiple outputs, when providing the `metrics` argument as a list, it should have as many entries as the model has outputs. Received:\nmetrics=['accuracy']\nof length 1 whereas the model has 2 outputs."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('stats150.csv')\n",
    "\n",
    "# Function to split training focus\n",
    "def split_training_focus(row):\n",
    "    words = [word.strip() for word in row.split(',')]\n",
    "    return pd.Series([words[0], words[1]])\n",
    "\n",
    "# Applying the function to the DataFrame\n",
    "df[['T1 Focus', 'T2 Focus']] = df['Recommended Training Focus'].apply(split_training_focus)\n",
    "\n",
    "# Drop the original 'Recommended Training Focus' column\n",
    "df = df.drop(columns=['Recommended Training Focus'])\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder_position = LabelEncoder()\n",
    "df['Position'] = label_encoder_position.fit_transform(df['Position'])\n",
    "\n",
    "label_encoder_t1 = LabelEncoder()\n",
    "df['T1 Focus'] = label_encoder_t1.fit_transform(df['T1 Focus'])\n",
    "\n",
    "label_encoder_t2 = LabelEncoder()\n",
    "df['T2 Focus'] = label_encoder_t2.fit_transform(df['T2 Focus'])\n",
    "\n",
    "# Dropping non-numeric and target columns\n",
    "X = df.drop(columns=['Player ID', 'Name', 'T1 Focus', 'T2 Focus'])\n",
    "y_t1 = to_categorical(df['T1 Focus'])\n",
    "y_t2 = to_categorical(df['T2 Focus'])\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_t1_train, y_t1_test, y_t2_train, y_t2_test = train_test_split(X_scaled, y_t1, y_t2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the neural network model\n",
    "input_layer = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "# Shared hidden layers\n",
    "hidden_layer1 = Dense(64, activation='relu')(input_layer)\n",
    "hidden_layer2 = Dense(32, activation='relu')(hidden_layer1)\n",
    "\n",
    "# Output layers for T1 Focus and T2 Focus\n",
    "t1_output = Dense(y_t1.shape[1], activation='softmax', name='t1_output')(hidden_layer2)\n",
    "t2_output = Dense(y_t2.shape[1], activation='softmax', name='t2_output')(hidden_layer2)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=[t1_output, t2_output])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, [y_t1_train, y_t2_train], epochs=50, batch_size=32, validation_data=(X_test, [y_t1_test, y_t2_test]))\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation = model.evaluate(X_test, [y_t1_test, y_t2_test])\n",
    "\n",
    "# Output evaluation results\n",
    "print(f\"Overall Loss: {evaluation[0]}\")\n",
    "print(f\"T1 Focus - Loss: {evaluation[1]}, Accuracy: {evaluation[3]}\")\n",
    "print(f\"T2 Focus - Loss: {evaluation[2]}, Accuracy: {evaluation[4]}\")\n",
    "\n",
    "# Example new player data for prediction\n",
    "new_player_df = [[19, 0, 20, 5, 1, 40, 600, 220, 100, 2, 8, 12]]\n",
    "\n",
    "# Encode and scale the new player data\n",
    "new_player_scaled = scaler.transform(new_player_df)\n",
    "\n",
    "# Predict using the trained model\n",
    "new_prediction = model.predict(new_player_scaled)\n",
    "t1_focus_pred = label_encoder_t1.inverse_transform(np.argmax(new_prediction[0], axis=1))\n",
    "t2_focus_pred = label_encoder_t2.inverse_transform(np.argmax(new_prediction[1], axis=1))\n",
    "\n",
    "print(\"Predicted T1 Focus:\", t1_focus_pred[0])\n",
    "print(\"Predicted T2 Focus:\", t2_focus_pred[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c31ebe6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mangaliso/Desktop/Honours Project/test_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mangaliso/Desktop/Honours Project/test_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model.save('/home/mangaliso/Desktop/Honours Project/test_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0c4d932",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mangaliso/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('/home/mangaliso/Desktop/Honours Project/test/my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec8d9229",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_position = label_encoder_position.inverse_transform(df['Position'])\n",
    "decoded_t1_focus = label_encoder_t1.inverse_transform(df['T1 Focus'])\n",
    "decoded_t2_focus = label_encoder_t2.inverse_transform(df['T2 Focus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a85018b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Forward', 'Midfielder', 'Defender', 'Goalkeeper', 'Forward',\n",
       "       'Midfielder', 'Defender', 'Forward', 'Midfielder', 'Goalkeeper',\n",
       "       'Forward', 'Midfielder', 'Defender', 'Goalkeeper', 'Forward',\n",
       "       'Midfielder', 'Defender', 'Goalkeeper', 'Forward', 'Midfielder',\n",
       "       'Defender', 'Goalkeeper', 'Forward', 'Midfielder', 'Defender',\n",
       "       'Goalkeeper', 'Forward', 'Midfielder', 'Defender', 'Goalkeeper',\n",
       "       'Forward', 'Midfielder', 'Defender', 'Goalkeeper', 'Forward',\n",
       "       'Midfielder', 'Defender', 'Goalkeeper', 'Forward', 'Midfielder',\n",
       "       'Defender', 'Goalkeeper', 'Forward', 'Midfielder', 'Defender',\n",
       "       'Goalkeeper', 'Forward', 'Midfielder', 'Defender', 'Goalkeeper',\n",
       "       'Forward', 'Midfielder', 'Defender', 'Goalkeeper', 'Midfielder',\n",
       "       'Defender', 'Forward', 'Goalkeeper', 'Defender', 'Midfielder',\n",
       "       'Forward', 'Midfielder', 'Defender', 'Goalkeeper', 'Forward',\n",
       "       'Defender', 'Midfielder', 'Defender', 'Forward', 'Goalkeeper',\n",
       "       'Midfielder', 'Defender', 'Goalkeeper', 'Forward', 'Defender',\n",
       "       'Midfielder', 'Defender', 'Forward', 'Goalkeeper', 'Midfielder',\n",
       "       'Defender', 'Goalkeeper', 'Midfielder', 'Defender', 'Forward',\n",
       "       'Midfielder', 'Goalkeeper', 'Defender', 'Forward', 'Midfielder',\n",
       "       'Goalkeeper', 'Defender', 'Forward', 'Midfielder', 'Defender',\n",
       "       'Forward', 'Midfielder', 'Goalkeeper', 'Midfielder', 'Forward',\n",
       "       'Defender', 'Midfielder', 'Goalkeeper', 'Defender', 'Forward',\n",
       "       'Midfielder', 'Goalkeeper', 'Defender', 'Forward', 'Midfielder',\n",
       "       'Defender', 'Forward', 'Midfielder', 'Goalkeeper', 'Defender',\n",
       "       'Forward', 'Midfielder', 'Goalkeeper', 'Defender', 'Midfielder',\n",
       "       'Forward', 'Defender', 'Goalkeeper', 'Midfielder', 'Forward',\n",
       "       'Defender', 'Goalkeeper', 'Midfielder', 'Defender', 'Goalkeeper',\n",
       "       'Midfielder', 'Defender', 'Forward', 'Midfielder', 'Goalkeeper',\n",
       "       'Forward', 'Defender', 'Midfielder', 'Forward', 'Goalkeeper',\n",
       "       'Midfielder', 'Defender', 'Goalkeeper', 'Midfielder', 'Defender',\n",
       "       'Goalkeeper', 'Midfielder', 'Forward', 'Defender', 'Goalkeeper'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3e09b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position Mapping: {0: 'Defender', 1: 'Forward', 2: 'Goalkeeper', 3: 'Midfielder'}\n",
      "T1 Focus Mapping: {0: 'Endurance', 1: 'Passing', 2: 'Reflexes', 3: 'Shooting', 4: 'Speed', 5: 'Stamina', 6: 'Strength', 7: 'Tackling'}\n",
      "T2 Focus Mapping: {0: 'Agility', 1: 'Ball Control', 2: 'Communication', 3: 'Concentration', 4: 'Dribbling', 5: 'Endurance', 6: 'Passing Accuracy', 7: 'Positioning', 8: 'Shooting Accuracy', 9: 'Shooting Technique', 10: 'Speed', 11: 'Stamina', 12: 'Strength', 13: 'Tackling', 14: 'Vision'}\n"
     ]
    }
   ],
   "source": [
    "position_mapping = dict(zip(label_encoder_position.transform(label_encoder_position.classes_), label_encoder_position.classes_))\n",
    "t1_focus_mapping = dict(zip(label_encoder_t1.transform(label_encoder_t1.classes_), label_encoder_t1.classes_))\n",
    "t2_focus_mapping = dict(zip(label_encoder_t2.transform(label_encoder_t2.classes_), label_encoder_t2.classes_))\n",
    "\n",
    "# Print mappings (optional)\n",
    "print(\"Position Mapping:\", position_mapping)\n",
    "print(\"T1 Focus Mapping:\", t1_focus_mapping)\n",
    "print(\"T2 Focus Mapping:\", t2_focus_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecbf02bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder_t2.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(label_encoder_t1, 'label_encoder_t1.joblib')\n",
    "joblib.dump(label_encoder_t2, 'label_encoder_t2.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48387627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "#Save label encoders as JSON\n",
    "with open('label_encoder_t1.json', 'w') as f:\n",
    "    json.dump(label_encoder_t1.classes_.tolist(), f)\n",
    "\n",
    "with open('label_encoder_t2.json', 'w') as f:\n",
    "    json.dump(label_encoder_t2.classes_.tolist(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2deee0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
